{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import shapefile\n",
    "from shapely.geometry import shape, mapping, Point, Polygon\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import descartes\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_path = 'Data/test_data_042819.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tornado Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates for tornado disasters in Columbus, 1950-2010: http://www.usa.com/columbus-oh-natural-disasters-extremes.htm\n",
    "tornado_df = pd.read_csv(\"Data/HistoricalTornadoEvents.csv\")\n",
    "tornado_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "def deg_to_decimal(d, m, s, direction):\n",
    "    res = int(d) + float(m)/60 + float(s)/3600\n",
    "    if direction in ('S','W'):\n",
    "        res *= -1\n",
    "    return res\n",
    "\n",
    "def tornado_df_coords(str_col):\n",
    "    tornado_arr = np.array(tornado_df[str_col])\n",
    "    coords = [coord.split(\" / \") for coord in tornado_arr]\n",
    "\n",
    "    p = re.compile('(\\d+)Â°(\\d+)\\'([N|S|E|W])')\n",
    "    coords_new = []\n",
    "    for lat_long in coords:\n",
    "        lat = p.match(lat_long[0])\n",
    "        lat_dd = deg_to_decimal(lat.group(1), lat.group(2), 0, lat.group(3))\n",
    "\n",
    "        long = p.match(lat_long[1])\n",
    "        long_dd = deg_to_decimal(long.group(1), long.group(2), 0, long.group(3))\n",
    "        \n",
    "        coords_new.append([lat_dd, long_dd])\n",
    "\n",
    "    return coords_new\n",
    "\n",
    "starts = tornado_df_coords('Start Lat/Log')\n",
    "ends = tornado_df_coords('End Lat/Log')\n",
    "\n",
    "def convert(coords):\n",
    "    lat = [coords[i][0] for i in range(len(coords))]\n",
    "    long = [coords[i][1] for i in range(len(coords))]\n",
    "    dist = 2*list(tornado_df[\"Distance (miles)\"])\n",
    "    magnitude = 2*list(tornado_df[\"Magnitude\"])\n",
    "    \n",
    "    p = re.compile('(\\d+.\\d+)\\sMile[s]*')\n",
    "    length = [float(p.match(l).group(1)) for l in 2*list(tornado_df[\"Length\"])]\n",
    "    \n",
    "    d = {\"Lat\": lat, \"Long\": long, \"Distance\": dist, \"Magnitude\": magnitude, \"Length\": length}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n",
    "\n",
    "dist_mag_tornado_df = convert(starts+ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest = pd.read_excel(train_test_path) # traintest has 158 rows\n",
    "\n",
    "# find matching coordinates with smallest distance\n",
    "def calc_smallest_dist_tornado(comp):\n",
    "    d = []\n",
    "    vals = {\"Distance\": [], \"Magnitude\": [], \"Length\": []}\n",
    "    km_per_mi = 1.60934\n",
    "    for outer in range(len(traintest)):\n",
    "        smallest = np.inf\n",
    "        tornado_dist = 0\n",
    "        tornado_mag = 0\n",
    "        tornado_length = 0\n",
    "#         traintest_coord = LatLon.LatLon(Latitude(traintest.loc[outer, 'Latitude']), Longitude(traintest.loc[outer, 'Longitude']))\n",
    "#         comp_coord = LatLon(Latitude(comp.loc[ctr, 'Lat']), Longitude(comp.loc[ctr, 'Long']))\n",
    "        for ctr in range(len(comp)):\n",
    "            dist = np.sqrt(((traintest.loc[outer, 'Latitude'] - comp.loc[ctr, 'Lat']) ** 2) + ((traintest.loc[outer, 'Longitude'] - comp.loc[ctr, 'Long']) ** 2))\n",
    "#             dist = traintest_coord.distance(comp_coord) * km_per_mi\n",
    "            if dist < smallest:\n",
    "                smallest = dist\n",
    "                tornado_dist = comp.loc[ctr, 'Distance']\n",
    "                tornado_mag = int(comp.loc[ctr, 'Magnitude'])\n",
    "                tornado_length = comp.loc[ctr, 'Length']\n",
    "        d.append(smallest)\n",
    "        vals[\"Distance\"].append(tornado_dist)\n",
    "        vals[\"Magnitude\"].append(tornado_mag)\n",
    "        vals[\"Length\"].append(tornado_length)\n",
    "    return (d, vals)\n",
    "\n",
    "distances, vals = calc_smallest_dist_tornado(dist_mag_tornado_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vals = {\"Distance\": [], \"Magnitude\": []}\n",
    "\n",
    "# if dist < tornado_length/69, leave as is, or it will be None (further than 1 mile)\n",
    "miles_per_deg = 69\n",
    "for ctr in range(len(distances)):\n",
    "    miles_within = vals[\"Length\"][ctr]\n",
    "    if distances[ctr] < miles_within/miles_per_deg:\n",
    "        final_vals[\"Distance\"].append(vals[\"Distance\"][ctr])\n",
    "        final_vals[\"Magnitude\"].append(vals[\"Magnitude\"][ctr])\n",
    "    else:\n",
    "        final_vals[\"Distance\"].append(0)\n",
    "        final_vals[\"Magnitude\"].append(0)\n",
    "    \n",
    "# df here is doing to be the final DF with distance/magnitude for each point in train/test data\n",
    "# d = {\"Lat\": traintest['Latitude'], \"Long\": traintest['Longitude'], \"Distance\": final_vals[\"Distance\"], \"Magnitude\": final_vals[\"Magnitude\"]}\n",
    "\n",
    "# unnecessary\n",
    "# df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given GEOID, return series that contains the Area and geometry of GEOID\n",
    "def getMatchingGEOIDData(geoid):\n",
    "    return gdf[gdf[\"GEOID\"] == int(geoid)][[\"Area\", \"geometry\"]]\n",
    "\n",
    "# Return the county name where GEOID is in \n",
    "def geoidToCountyLatLong(geoid):\n",
    "    countyCode = int(geoid / 10000000)\n",
    "    return county_data[county_data[\"GEOID\"] == countyCode][[\"NAME\"]]\n",
    "\n",
    "# Return the GEOID of the given coordinates\n",
    "def pointToGeoid(long, lat):\n",
    "    type1 = type(long)\n",
    "    type2 = type(lat)\n",
    "    assert(type1 == type2), \"Parameters must be the same type\"\n",
    "    _pnts = []\n",
    "    \n",
    "    if (type1 == list):\n",
    "        assert(len(long) == len(lat)), \"Parameters must have same length\"\n",
    "        for i in range(len(long)):\n",
    "            _pnts.append(Point(long[i], lat[i]))\n",
    "    else:\n",
    "        _pnts.append(Point(long, lat))\n",
    "        \n",
    "    pnts = gpd.GeoDataFrame(geometry=_pnts)\n",
    "    for _, row in gdf_original.iterrows():\n",
    "        if pnts.within(row.geometry)[0]:\n",
    "            return row.GEOID\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "def getGeoidPopulation(geoid):\n",
    "    population = ohio_population_data[ohio_population_data['GEOID'] == int(geoid)][\"2010 Total Population\"]\n",
    "    return population[0] if population.size == 1 else 0.0\n",
    "\n",
    "def getGeoidArea(geoid):\n",
    "    area = ohio_population_data[ohio_population_data['GEOID'] == int(geoid)][\"Area (square miles)\"]\n",
    "    return area[0] if area.size == 1 else 0.0\n",
    "\n",
    "def getGeoidCountyName(geoid):\n",
    "    county = ohio_population_data[ohio_population_data['GEOID'] == int(geoid)][\"CountyNames\"]\n",
    "    return county[0] if county.size == 1 else \"\"\n",
    "\n",
    "# Returns copy of df with GEOID and data relevant to GEOID to df\n",
    "# If lat long not associated with a GEOID, population and area = 0.0 and CountyName = \"\" \n",
    "# Precondition: df is a dataframe\n",
    "def addGeoidColumns(df):\n",
    "    assert('Longitude' in df.columns), \"Cannot find longitude column\"\n",
    "    assert('Latitude' in df.columns), \"Cannot find latitude column\"\n",
    "    df_copy = df.copy(deep=False)\n",
    "    \n",
    "    geoidData = df_copy.apply(lambda x: pointToGeoid(x['Longitude'], x['Latitude']), axis=1)\n",
    "    df_copy = df_copy.assign(GEOID=geoidData.values)\n",
    "    populationData = df_copy.apply(lambda x: getGeoidPopulation(x['GEOID']), axis=1)\n",
    "    areaData = df_copy.apply(lambda x: getGeoidArea(x['GEOID']), axis=1)\n",
    "    #countyData = df_copy.apply(lambda x: getGeoidCountyName(x['GEOID']), axis=1)\n",
    "    df['Pop_Den'] = populationData / areaData\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_excel(\"Data/Columbus_Population.xlsx\").iloc[:,0:2]\n",
    "geoids = census_data.iloc[:,0]\n",
    "\n",
    "# CREDIT TO http://andrewgaidus.com/Reading_Zipped_Shapefiles/, used to parse census data taken from\n",
    "# .dbf, .prj, .shp, and .shx files\n",
    "zipFile = ZipFile(\"Data/ohio_tigerfiles.zip\")\n",
    "filenames = [y for y in sorted(zipFile.namelist()) for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)] \n",
    "dbf, prj, shp, shx = [BytesIO(zipFile.read(filename)) for filename in filenames]\n",
    "\n",
    "reader = shapefile.Reader(shp=shp, shx=shx, dbf=dbf)\n",
    "attributes, geometry = [], []\n",
    "field_names = [field[0] for field in reader.fields[1:]]  \n",
    "for row in reader.shapeRecords():  \n",
    "    geometry.append(shape(row.shape.__geo_interface__))\n",
    "    attributes.append(dict(zip(field_names, row.record)))\n",
    "    \n",
    "# Put tigerfiles into GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data = attributes, geometry = geometry)[[\"ALAND10\", \"GEOID10\", \"geometry\"]]\n",
    "gdf = gdf.rename(index=str, columns={\"ALAND10\": \"Area\", \"GEOID10\": \"GEOID\"})\n",
    "gdf.GEOID = gdf.GEOID.astype(int)\n",
    "gdf = gdf[gdf[\"GEOID\"].isin(geoids)] # Only get data on GEOIDs that match census data above\n",
    "\n",
    "# Latitude/Longitude ordering is switched, swap it back and add it as the \"geometry\" column\n",
    "block_coord_array = []\n",
    "for _, row in gdf.iterrows():\n",
    "    row_coord_array = []\n",
    "    for coord in mapping(row['geometry'])['coordinates'][0]:\n",
    "        correct_coord = reversed(coord)\n",
    "        row_coord_array.append(list(correct_coord))\n",
    "    \n",
    "    block_coord_array.append(row_coord_array)\n",
    "    \n",
    "gdf_original = gdf.copy(deep=True)\n",
    "gdf[\"geometry\"] = pd.Series(block_coord_array, index=gdf.index)\n",
    "\n",
    "blockRows = geoids.apply(getMatchingGEOIDData) #An array of DF rows\n",
    "\n",
    "block_df = pd.DataFrame()\n",
    "for row in blockRows:\n",
    "    block_df = block_df.append(row, ignore_index=True)\n",
    "    \n",
    "ohio_population_data = census_data.join(block_df)\n",
    "\n",
    "county_data = pd.read_excel(\"Data/Ohio_GEOID_Conversion.xlsx\").iloc[:,1:4]\n",
    "\n",
    "# geoids is only restricted to columbus\n",
    "countyRows = geoids.apply(geoidToCountyLatLong)\n",
    "county_df = pd.DataFrame()\n",
    "for county in countyRows:\n",
    "    county_df = county_df.append(county, ignore_index=True)\n",
    "    \n",
    "ohio_population_data[\"CountyNames\"] = pd.Series(county_df.NAME.values, index=ohio_population_data.index)\n",
    "ohio_population_data = ohio_population_data.rename(index=str, columns={\"Area\": \"Area (square miles)\"})\n",
    "\n",
    "# Convert square meters to square miles\n",
    "ohio_population_data[\"Area (square miles)\"] = ohio_population_data[\"Area (square miles)\"] / 2589988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here, endingDF is DF with population density for each coordinate\n",
    "# test_data = pd.read_csv(\"./Data/Training.csv\")\n",
    "# endingDF = addGeoidColumns(test_data)\n",
    "# endingDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point of Interest Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points of Interest file - includes all popular areas in Columbus, OH\n",
    "# Source: http://opendata.columbus.gov/datasets/86458e5d8a264dff9204518e109c0f93_10?geometry=-83.926%2C39.846%2C-82.168%2C40.214&page=7\n",
    "poi_df = pd.read_csv('Data/Points_of_Interest.csv')\n",
    "\n",
    "#drop irrelevant columns\n",
    "poi_df = poi_df.drop(['POI_SOURCE', 'WEBSITE', 'OB_GYN', 'PEDIATRICS', 'PRIMARY_CARE'], axis=1)\n",
    "\n",
    "zeros = ['Emergency', 'Medical', 'Industrial']\n",
    "ones = ['Government', 'Group Quarters', 'Education']\n",
    "twos = ['Transportation', 'Public Places', 'Retail', 'Office']\n",
    "\n",
    "poi = poi_df[['X', 'Y', 'POI_TYPE']].copy()\n",
    "\n",
    "# match all strings = 'category - subcategory' and remove the part immediately following the\n",
    "# '-' to end with 'category'\n",
    "\n",
    "new_poi = poi.replace(to_replace=r' - .*', value='', regex=True)\n",
    "new_poi['Classification'] = new_poi['POI_TYPE']\n",
    "new_poi['Classification'].replace({'Emergency': 0, 'Medical': 0, 'Industrial': 0, 'Government': 1, \n",
    "                                             'Group Quarters': 1, 'Education': 1, 'Transportation': 2, \n",
    "                                             'Public Places': 2, 'Retail': 2, 'Office': 2}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make this the previous DF generated by past cells\n",
    "traintest = pd.read_excel(train_test_path) # traintest has 158 rows\n",
    "distances = []\n",
    "classifications = []\n",
    "final_distances = []\n",
    "final_classifications = []\n",
    "\n",
    "# find matching coordinates with smallest distance\n",
    "def calc_smallest_dist_poi(comp):\n",
    "    d = []\n",
    "    c = []\n",
    "    outer = 0\n",
    "    while outer < len(traintest):\n",
    "        ctr = 0\n",
    "        smallest = np.inf\n",
    "        cls = 0 # 0, 1, or 2\n",
    "        while ctr < len(comp): # go through 15,000 rows\n",
    "            dist = np.sqrt(((traintest.loc[outer, 'Latitude'] - comp.loc[ctr, 'Y']) ** 2) + ((traintest.loc[outer, 'Longitude'] - comp.loc[ctr, 'X']) ** 2))\n",
    "            if dist < smallest:\n",
    "                smallest = dist\n",
    "                cls = comp.loc[ctr, 'Classification']\n",
    "            ctr += 1\n",
    "        d.append(smallest)\n",
    "        c.append(cls)\n",
    "        outer += 1\n",
    "    return (d, c)\n",
    "\n",
    "distances, classifications = calc_smallest_dist_poi(new_poi)\n",
    "\n",
    "# if dist < 1/69, leave as is, or it will be None (further than 1 mile)\n",
    "ctr = 0\n",
    "for i in distances:\n",
    "    if i < 1/69:\n",
    "        final_distances.append(i)\n",
    "        final_classifications.append(classifications[ctr])\n",
    "    else:\n",
    "        final_distances.append(None)\n",
    "        final_classifications.append(None)\n",
    "    ctr += 1\n",
    "\n",
    "# TODO: Add final_classifications as column in DF\n",
    "# final_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Tornado Distance</th>\n",
       "      <th>Tornado Magnitude</th>\n",
       "      <th>POI_TYPE</th>\n",
       "      <th>Pop_Den</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.087601</td>\n",
       "      <td>-83.003476</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3240.893082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.983963</td>\n",
       "      <td>-83.165229</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1552.374779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.129978</td>\n",
       "      <td>-82.806906</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>176.616850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.058561</td>\n",
       "      <td>-82.862060</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3536.998504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.884917</td>\n",
       "      <td>-82.957369</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1122.177611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude  Tornado Distance  Tornado Magnitude POI_TYPE  \\\n",
       "0  40.087601 -83.003476              13.1                  2        2   \n",
       "1  39.983963 -83.165229               5.2                  3        1   \n",
       "2  40.129978 -82.806906              15.2                  2     None   \n",
       "3  40.058561 -82.862060              12.6                  2        2   \n",
       "4  39.884917 -82.957369               5.5                  3        0   \n",
       "\n",
       "       Pop_Den  \n",
       "0  3240.893082  \n",
       "1  1552.374779  \n",
       "2   176.616850  \n",
       "3  3536.998504  \n",
       "4  1122.177611  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addFeatureData(df):\n",
    "    assert('Longitude' in df.columns), \"Cannot find longitude column\"\n",
    "    assert('Latitude' in df.columns), \"Cannot find latitude column\"\n",
    "    \n",
    "    # Add final_vals[\"Distance\"]\n",
    "    df['Tornado Distance'] = pd.Series(final_vals['Distance'], index=df.index)\n",
    "    \n",
    "    # Add final_vals[\"Magnitude\"]\n",
    "    df['Tornado Magnitude'] = pd.Series(final_vals['Magnitude'], index=df.index)\n",
    "    \n",
    "    # Add final_classifications\n",
    "    df['POI_TYPE'] = pd.Series(final_classifications, index=df.index)\n",
    "    \n",
    "    # Run addGeoidColumns\n",
    "    df = addGeoidColumns(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "total_train_test_data = pd.read_excel(train_test_path)\n",
    "allFeatureDF = addFeatureData(total_train_test_data)\n",
    "allFeatureDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeatureDF['Pop_Den'] = allFeatureDF['Pop_Den'].fillna((allFeatureDF['Pop_Den'].mean()))\n",
    "allFeatureDF['POI_TYPE'] = allFeatureDF['POI_TYPE'].replace('None', (allFeatureDF['POI_TYPE'].mode())[0])\n",
    "allFeatureDF['POI_TYPE'] = allFeatureDF['POI_TYPE'].replace(np.NaN, (allFeatureDF['POI_TYPE'].mode())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeatureDF.to_csv(\"REAL_DATA.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
